{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train_b = pd.read_excel('./Train/train_bureau.xlsx',engine='openpyxl')\n",
    "df_train_data = pd.read_excel('./Train/train_Data.xlsx',engine='openpyxl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_b = pd.read_excel('./Test/test_bureau.xlsx',engine='openpyxl')\n",
    "df_test_data = pd.read_excel('./Test/test_Data.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128655, 92)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clmn_list = ['SELF-INDICATOR', 'MATCH-TYPE', 'ACCT-TYPE', 'CONTRIBUTOR-TYPE', \n",
    "             'OWNERSHIP-IND','ACCOUNT-STATUS','INSTALLMENT-FREQUENCY','ASSET_CLASS']\n",
    "\n",
    "df_train_b['ASSET_CLASS'] = df_train_b.groupby('ID')['ASSET_CLASS'].ffill()\n",
    "# df_train_b['ASSET_CLASS'].value_counts()\n",
    "\n",
    "df_train_b['ASSET_CLASS'].fillna('NSFD',inplace=True)\n",
    "# df_train_b['ASSET_CLASS'].value_counts()\n",
    "\n",
    "def Mrgd_df_all(lst):\n",
    "    df_lst = []\n",
    "    for f in lst:\n",
    "        df = df_train_b.groupby('ID')[f].value_counts().unstack().add_prefix(f+'_').fillna(0)\n",
    "        df_lst.append(df)\n",
    "\n",
    "    return df_lst\n",
    "\n",
    "#drop installment frequency and fill Asset class missing values\n",
    "df_train_b.drop('INSTALLMENT-FREQUENCY',axis=1,inplace=True)\n",
    "clmn_list.remove('INSTALLMENT-FREQUENCY')\n",
    "\n",
    "result_a2 = pd.concat(Mrgd_df_all(clmn_list), join='inner', axis=1)\n",
    "result_a2.reset_index(inplace=True)\n",
    "result_a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128655, 99)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_b['INSTALLMENT-AMT'] = df_train_b['INSTALLMENT-AMT'].apply(lambda x: str(x).split('/')[0])\n",
    "\n",
    "#'CREDIT-LIMIT/SANC AMT' ,'DISBURSED-AMT/HIGH CREDIT', 'INSTALLMENT-AMT' ,'CURRENT-BAL' ,'OVERDUE-AMT', 'WRITE-OFF-AMT', 'TENURE'\n",
    "# del result_b1,tl_df,df_lst\n",
    "def total_ammount(cmn_nm):\n",
    "    '''use only when needed'''\n",
    "    df_lst=[]\n",
    "    tl_df = pd.DataFrame()\n",
    "    for cm in cmn_nm:\n",
    "        if type(df_train_b[cm][0]) != np.float64:\n",
    "            df_train_b[cm] = df_train_b[cm].str.replace(',', '').astype(float)\n",
    "        tl_df= df_train_b.groupby('ID')[cm].sum()\n",
    "        df_lst.append(tl_df)\n",
    "\n",
    "    return(df_lst)\n",
    "\n",
    "tl_clmn_list = ['CREDIT-LIMIT/SANC AMT' ,'DISBURSED-AMT/HIGH CREDIT', 'INSTALLMENT-AMT' ,'CURRENT-BAL' ,'OVERDUE-AMT', 'WRITE-OFF-AMT', 'TENURE']\n",
    "result_b1 = pd.concat(total_ammount(tl_clmn_list), join='inner', axis=1).add_prefix('Total_')\n",
    "result_b1.reset_index(inplace=True)\n",
    "result_b1.shape\n",
    "\n",
    "bureua_data_f =pd.merge(result_a2,result_b1,how='inner',on='ID',)\n",
    "bureua_data_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128655, 103)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_sums = ['DATE-REPORTED','DISBURSED-DT','CLOSE-DT','LAST-PAYMENT-DATE']\n",
    "rb2= df_train_b.groupby('ID')[other_sums].count().reset_index()\n",
    "# rb2.head()\n",
    "\n",
    "rb2.rename(columns={'ID':'ID',\n",
    "            'DATE-REPORTED':'Total_Times_reported',\n",
    "            'DISBURSED-DT':'Total_Times_disbursed',\n",
    "            'CLOSE-DT':'Total_Times_closed',\n",
    "            'LAST-PAYMENT-DATE':'Total_last_payments'},inplace=True)\n",
    "\n",
    "bureua_data_f =pd.merge(bureua_data_f,rb2,how='inner',on='ID',)\n",
    "bureua_data_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128655, 104)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_b['REPORTED DATE - HIST']  = df_train_b['REPORTED DATE - HIST'].apply(lambda x: x.split(',') if type(x)==str else x).apply(lambda x: x[:-1] if type(x)==list else x)\n",
    "df_train_b['REPORTED DATE - HIST'] = df_train_b['REPORTED DATE - HIST'].apply(lambda x: len(x) if type(x)==list else x)\n",
    "rc1 = df_train_b.groupby('ID')['REPORTED DATE - HIST'].sum().reset_index()\n",
    "\n",
    "rc1.columns = ['ID','Total_Times_Reported']\n",
    "bureua_data_f =pd.merge(bureua_data_f,rc1,how='inner',on='ID',)\n",
    "bureua_data_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128655, 107)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def amt_sum(clm,df):\n",
    "    for cl in clm:\n",
    "        df[cl] = df[cl].apply(lambda x: list(filter(lambda item: item,x.split(','))) if type(x)==str else x) #remove comma\n",
    "        df[cl] = df[cl].apply(lambda d: d if isinstance(d, list) else [0.0])#fill na\n",
    "        df[cl] = df[cl].apply(lambda x: list(map(float,x)) if type(x)==list else x)#convert all the list elements to float\n",
    "        df[cl] = df[cl].apply(lambda x:sum(x))#summ the ammount\n",
    "\n",
    "amt_sm_cl = ['CUR BAL - HIST','AMT OVERDUE - HIST','AMT PAID - HIST']\n",
    "amt_sum(amt_sm_cl,df_train_b)\n",
    "\n",
    "rd1 = df_train_b.groupby('ID')[amt_sm_cl].sum().reset_index()\n",
    "rd1.rename(columns={'ID':'ID','CUR BAL - HIST':'Total_CUR_BAL','AMT OVERDUE - HIST':'Total_Overdue_Amt','AMT PAID - HIST':'Total_Paid_Amt'})\n",
    "\n",
    "bureua_data_f =pd.merge(bureua_data_f,rd1,how='inner',on='ID',)\n",
    "bureua_data_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128655, 108)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textwrap\n",
    "def for_scN_DPD(nu):\n",
    "    if 'E' in nu:\n",
    "        nu = '%f'%np.float64(nu)\n",
    "        nu = textwrap.wrap(nu,3)\n",
    "        # print(nu)\n",
    "        nu =list(map(float,nu))\n",
    "\n",
    "    return sum(nu)\n",
    "\n",
    "#split into part of 3 digits\n",
    "#check if its string\n",
    "#if its not filter out keep only ints\n",
    "#sum the total of list\n",
    "def clean_DPD(x):\n",
    "    wp = textwrap.wrap(x,3)\n",
    "    if not all(str(s).isdigit() for s in wp):\n",
    "        # print(wp\n",
    "        wp = list(filter(lambda x: x not in ['XXX','DDD'], wp))\n",
    "        wp = list(map(int, wp))\n",
    "    else:\n",
    "        wp = list(map(int,wp))\n",
    "\n",
    "    return sum(wp)\n",
    "\n",
    "# for_scN_DPD(df_train_b['DPD - HIST'][26])\n",
    "df_train_b['DPD - HIST'].fillna('000',inplace=True)\n",
    "df_train_b['DPD - HIST'] = df_train_b['DPD - HIST'].apply(lambda x:for_scN_DPD(x) if 'E' in x else clean_DPD(x))\n",
    "rd3 = df_train_b.groupby('ID')['DPD - HIST'].sum().reset_index()\n",
    "\n",
    "rd3.columns = ['ID','Total_DPD']\n",
    "bureua_data_f =pd.merge(bureua_data_f,rd3,how='inner',on='ID',)\n",
    "bureua_data_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "print(len(result_a2.columns))\n",
    "def drop_VC_BL_100(clm_nm,data_f):\n",
    "    for i in df_train_b[clm_nm].value_counts().loc[lambda x : x<100].index:\n",
    "        data_f.drop(clm_nm+'_%s'%i,axis=1,inplace=True)\n",
    "\n",
    "#now for CONTRIBUTOR-TYPE_ ACCOUNT-STATUS_ ASSET_CLASS_\n",
    "# for cl in ['ACCT-TYPE','CONTRIBUTOR-TYPE','ACCOUNT-STATUS','ASSET_CLASS']:\n",
    "#     drop_VC_BL_100(cl,result_a2)\n",
    "\n",
    "print(len(result_a2.columns))\n",
    "\n",
    "for cl in ['ACCT-TYPE','CONTRIBUTOR-TYPE','ACCOUNT-STATUS','ASSET_CLASS']:\n",
    "    drop_VC_BL_100(cl,bureua_data_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mss_ct(ref_cl,ms_cl,df):\n",
    "    ''' function to fill the NaN values by mode method\n",
    "        Ex: in Particular State which is more frequent occured city\n",
    "            same for Area in Area\n",
    "                     SEX in Area\n",
    "                     Age in Area\n",
    "                     Salary in Area\n",
    "        ref_cl : Referece Column,\n",
    "        ref_nm : Element of refernce column, \n",
    "        df     : dataframe to oerform fill na operation\n",
    "    \n",
    "    '''\n",
    "    md = df[ms_cl].mode()[0]\n",
    "    frqnt_val = lambda x: x.fillna(x.value_counts().idxmax() if x.value_counts().max() >=1 else md , inplace = False)\n",
    "    df[ms_cl]=df.groupby([ref_cl])[ms_cl].apply(frqnt_val)\n",
    "    df[ms_cl] = df[ms_cl].fillna(df[ms_cl].value_counts().idxmax())\n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BARDDHAMAN', 894) ('GUNTUR', 1756)\n",
      "('BARDDHAMAN', 1820) ('GUNTUR', 3172)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def find_VC_St(ref_cl,ref_nm,tg):\n",
    "    ''' ref_cl : Referece Column,\n",
    "        ref_nm : Element of refernce column,\n",
    "        tg     : column name to fill nan   '''\n",
    "    vl_cm =df_train_data[df_train_data[ref_cl]==ref_nm][tg].value_counts()\n",
    "#     print(vl_cm)\n",
    "    re_nm_tg_cnt = (vl_cm.index[0],vl_cm[0])\n",
    "    return re_nm_tg_cnt\n",
    "\n",
    "print(find_VC_St('State','WEST BENGAL','City'),find_VC_St('State','ANDHRA PRADESH','City'))\n",
    "\n",
    "mss_ct('State','City',df_train_data)\n",
    "mss_ct('City','Area',df_train_data)\n",
    "mss_ct('Area','SEX',df_train_data)\n",
    "mss_ct('Area','AGE',df_train_data)\n",
    "mss_ct('Area','MonthlyIncome',df_train_data)\n",
    "\n",
    "print(find_VC_St('State','WEST BENGAL','City'),find_VC_St('State','ANDHRA PRADESH','City'))\n",
    "df_train_data['MaturityDAte'].fillna(method='ffill',inplace=True)\n",
    "print(any(df_train_data.isna().sum()>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "dro_clm = ['BranchID','AssetID','ManufacturerID','SupplierID','ZiPCODE']\n",
    "df_train_data.drop(dro_clm,axis=1,inplace=True)\n",
    "\n",
    "dt_cl = ['DisbursalDate','MaturityDAte','AuthDate']\n",
    "\n",
    "def handel_dt(clm):\n",
    "    for cl in clm:\n",
    "        df_train_data[cl+'_Year'] = df_train_data[cl].dt.year.astype(float)\n",
    "        df_train_data[cl+'_Month']= df_train_data[cl].dt.month.astype(float)\n",
    "        df_train_data[cl+'_Week']= df_train_data[cl].dt.week.astype(float)\n",
    "        df_train_data[cl+'_Day']= df_train_data[cl].dt.day.astype(float)\n",
    "\n",
    "handel_dt(dt_cl)\n",
    "df_train_data.drop(dt_cl,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = df_train_data['ID']\n",
    "target = df_train_data['Top-up Month']\n",
    "\n",
    "TUP_Mn = { id_en:i for i,id_en in enumerate(df_train_data['Top-up Month'].value_counts().index) }\n",
    "\n",
    "target = target.map(TUP_Mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before droping na (128655, 30)\n",
      "After droping na (128655, 30)\n"
     ]
    }
   ],
   "source": [
    "#since the target is Ordinal we can assign no top to 0\n",
    "#since the target is Ordinal we can assign no top to 0\n",
    "# TUP_Mn = { id_en:i for i,id_en in enumerate(df_train_data['Top-up Month'].value_counts().index) }\n",
    "\n",
    "print('Before droping na',df_train_data.shape)\n",
    "df_train_data.dropna(inplace=True)\n",
    "print('After droping na',df_train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category-encoders in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from category-encoders) (1.1.4)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from category-encoders) (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from category-encoders) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from category-encoders) (0.23.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from category-encoders) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from category-encoders) (1.5.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pandas>=0.21.1->category-encoders) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from pandas>=0.21.1->category-encoders) (2020.4)\n",
      "Requirement already satisfied: six in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from patsy>=0.5.1->category-encoders) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from scikit-learn>=0.20.0->category-encoders) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from scikit-learn>=0.20.0->category-encoders) (0.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n",
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "#Nominal cat features \n",
    "cat_ftrs = ['Frequency' ,'InstlmentMode' ,'LoanStatus', 'PaymentMode', 'Area' ,'SEX' ,'City' ,'State']\n",
    "\n",
    "!pip install category-encoders\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "# feature_list = list(all_train.columns)\n",
    "TE_encoder = TargetEncoder()\n",
    "# train_te = TE_encoder.fit_transform(df_train_data[cat_ftrs], target)\n",
    "\n",
    "for c in cat_ftrs:\n",
    "    TE_encoder.fit(df_train_data[c].values,target) \n",
    "    df_train_data[c] = TE_encoder.transform(list(df_train_data[c].values))\n",
    "    \n",
    "for c in cat_ftrs:\n",
    "    TE_encoder.fit(df_train_data[c].values,target) \n",
    "    df_test_data[c] = TE_encoder.transform(list(df_test_data[c].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 128655 entries, 0 to 128654\n",
      "Data columns (total 30 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   ID                   128655 non-null  int64  \n",
      " 1   Frequency            128655 non-null  float64\n",
      " 2   InstlmentMode        128655 non-null  float64\n",
      " 3   LoanStatus           128655 non-null  float64\n",
      " 4   PaymentMode          128655 non-null  float64\n",
      " 5   Area                 128655 non-null  float64\n",
      " 6   Tenure               128655 non-null  int64  \n",
      " 7   AssetCost            128655 non-null  int64  \n",
      " 8   AmountFinance        128655 non-null  float64\n",
      " 9   DisbursalAmount      128655 non-null  float64\n",
      " 10  EMI                  128655 non-null  float64\n",
      " 11  LTV                  128655 non-null  float64\n",
      " 12  SEX                  128655 non-null  float64\n",
      " 13  AGE                  128655 non-null  float64\n",
      " 14  MonthlyIncome        128655 non-null  float64\n",
      " 15  City                 128655 non-null  float64\n",
      " 16  State                128655 non-null  float64\n",
      " 17  Top-up Month         128655 non-null  object \n",
      " 18  DisbursalDate_Year   128655 non-null  float64\n",
      " 19  DisbursalDate_Month  128655 non-null  float64\n",
      " 20  DisbursalDate_Week   128655 non-null  float64\n",
      " 21  DisbursalDate_Day    128655 non-null  float64\n",
      " 22  MaturityDAte_Year    128655 non-null  float64\n",
      " 23  MaturityDAte_Month   128655 non-null  float64\n",
      " 24  MaturityDAte_Week    128655 non-null  float64\n",
      " 25  MaturityDAte_Day     128655 non-null  float64\n",
      " 26  AuthDate_Year        128655 non-null  float64\n",
      " 27  AuthDate_Month       128655 non-null  float64\n",
      " 28  AuthDate_Week        128655 non-null  float64\n",
      " 29  AuthDate_Day         128655 non-null  float64\n",
      "dtypes: float64(26), int64(3), object(1)\n",
      "memory usage: 30.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14745 entries, 0 to 14744\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   14745 non-null  int64  \n",
      " 1   Frequency            14745 non-null  float64\n",
      " 2   InstlmentMode        14745 non-null  float64\n",
      " 3   LoanStatus           14745 non-null  float64\n",
      " 4   PaymentMode          14745 non-null  float64\n",
      " 5   Area                 14745 non-null  float64\n",
      " 6   Tenure               14745 non-null  int64  \n",
      " 7   AssetCost            14745 non-null  int64  \n",
      " 8   AmountFinance        14745 non-null  float64\n",
      " 9   DisbursalAmount      14745 non-null  float64\n",
      " 10  EMI                  14745 non-null  float64\n",
      " 11  LTV                  14745 non-null  float64\n",
      " 12  SEX                  14745 non-null  float64\n",
      " 13  AGE                  14745 non-null  float64\n",
      " 14  MonthlyIncome        14745 non-null  float64\n",
      " 15  City                 14745 non-null  float64\n",
      " 16  State                14745 non-null  float64\n",
      " 17  DisbursalDate_Year   14745 non-null  float64\n",
      " 18  DisbursalDate_Month  14745 non-null  float64\n",
      " 19  DisbursalDate_Week   14745 non-null  float64\n",
      " 20  DisbursalDate_Day    14745 non-null  float64\n",
      " 21  MaturityDAte_Year    14745 non-null  float64\n",
      " 22  MaturityDAte_Month   14745 non-null  float64\n",
      " 23  MaturityDAte_Week    14745 non-null  float64\n",
      " 24  MaturityDAte_Day     14745 non-null  float64\n",
      " 25  AuthDate_Year        14745 non-null  float64\n",
      " 26  AuthDate_Month       14745 non-null  float64\n",
      " 27  AuthDate_Week        14745 non-null  float64\n",
      " 28  AuthDate_Day         14745 non-null  float64\n",
      "dtypes: float64(26), int64(3)\n",
      "memory usage: 3.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before droping na (128655, 114)\n",
      "After droping na (128655, 114)\n"
     ]
    }
   ],
   "source": [
    "all_train = pd.merge(bureua_data_f,df_train_data,how='inner',on='ID',)\n",
    "\n",
    "print('Before droping na',all_train.shape)\n",
    "all_train.dropna(inplace=True)\n",
    "print('After droping na',all_train.shape)\n",
    "all_train.drop(['ID','Top-up Month'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clmn_list = ['SELF-INDICATOR', 'MATCH-TYPE', 'ACCT-TYPE', 'CONTRIBUTOR-TYPE', \n",
    "#              'OWNERSHIP-IND','ACCOUNT-STATUS','INSTALLMENT-FREQUENCY','ASSET_CLASS']\n",
    "\n",
    "df_test_b['ASSET_CLASS'] = df_test_b.groupby('ID')['ASSET_CLASS'].ffill()\n",
    "# df_train_b['ASSET_CLASS'].value_counts()\n",
    "\n",
    "df_test_b['ASSET_CLASS'].fillna('NSFD',inplace=True)\n",
    "# df_train_b['ASSET_CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14745, 83)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Mrgd_df_all_ts(lst):\n",
    "    df_lst = []\n",
    "    for f in lst:\n",
    "        df = df_test_b.groupby('ID')[f].value_counts().unstack().add_prefix(f+'_').fillna(0)\n",
    "        df_lst.append(df)\n",
    "\n",
    "    return df_lst\n",
    "\n",
    "#drop installment frequency and fill Asset class missing values\n",
    "df_test_b.drop('INSTALLMENT-FREQUENCY',axis=1,inplace=True)\n",
    "# clmn_list.remove('INSTALLMENT-FREQUENCY')\n",
    "\n",
    "result_a2_ts = pd.concat(Mrgd_df_all_ts(clmn_list), join='inner', axis=1)\n",
    "result_a2_ts.reset_index(inplace=True)\n",
    "result_a2_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14745, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_b['INSTALLMENT-AMT'] = df_test_b['INSTALLMENT-AMT'].apply(lambda x: str(x).split('/')[0])\n",
    "\n",
    "#'CREDIT-LIMIT/SANC AMT' ,'DISBURSED-AMT/HIGH CREDIT', 'INSTALLMENT-AMT' ,'CURRENT-BAL' ,'OVERDUE-AMT', 'WRITE-OFF-AMT', 'TENURE'\n",
    "# del result_b1,tl_df,df_lst\n",
    "def total_ammount(cmn_nm):\n",
    "    '''use only when needed'''\n",
    "    df_lst=[]\n",
    "    tl_df = pd.DataFrame()\n",
    "    for cm in cmn_nm:\n",
    "        if type(df_test_b[cm][0]) != np.float64:\n",
    "            df_test_b[cm] = df_test_b[cm].str.replace(',', '').astype(float)\n",
    "        tl_df= df_test_b.groupby('ID')[cm].sum()\n",
    "        df_lst.append(tl_df)\n",
    "\n",
    "    return(df_lst)\n",
    "\n",
    "tl_clmn_list = ['CREDIT-LIMIT/SANC AMT' ,'DISBURSED-AMT/HIGH CREDIT', 'INSTALLMENT-AMT' ,'CURRENT-BAL' ,'OVERDUE-AMT', 'WRITE-OFF-AMT', 'TENURE']\n",
    "result_b1_ts = pd.concat(total_ammount(tl_clmn_list), join='inner', axis=1).add_prefix('Total_')\n",
    "result_b1_ts.reset_index(inplace=True)\n",
    "result_b1_ts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14745, 90)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureua_data_f_ts =pd.merge(result_a2_ts,result_b1_ts,how='inner',on='ID',)\n",
    "bureua_data_f_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14745, 94)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_sums = ['DATE-REPORTED','DISBURSED-DT','CLOSE-DT','LAST-PAYMENT-DATE']\n",
    "rb2_ts= df_test_b.groupby('ID')[other_sums].count().reset_index()\n",
    "# rb2.head()\n",
    "\n",
    "rb2_ts.rename(columns={'ID':'ID',\n",
    "            'DATE-REPORTED':'Total_Times_reported',\n",
    "            'DISBURSED-DT':'Total_Times_disbursed',\n",
    "            'CLOSE-DT':'Total_Times_closed',\n",
    "            'LAST-PAYMENT-DATE':'Total_last_payments'},inplace=True)\n",
    "\n",
    "bureua_data_f_ts =pd.merge(bureua_data_f_ts,rb2_ts,how='inner',on='ID',)\n",
    "bureua_data_f_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14745, 95)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_b['REPORTED DATE - HIST']  = df_test_b['REPORTED DATE - HIST'].apply(lambda x: x.split(',') if type(x)==str else x).apply(lambda x: x[:-1] if type(x)==list else x)\n",
    "df_test_b['REPORTED DATE - HIST'] = df_test_b['REPORTED DATE - HIST'].apply(lambda x: len(x) if type(x)==list else x)\n",
    "rc1_ts = df_test_b.groupby('ID')['REPORTED DATE - HIST'].sum().reset_index()\n",
    "\n",
    "rc1_ts.columns = ['ID','Total_Times_Reported']\n",
    "bureua_data_f_ts =pd.merge(bureua_data_f_ts,rc1_ts,how='inner',on='ID',)\n",
    "bureua_data_f_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14745, 98)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def amt_sum(clm,df):\n",
    "    for cl in clm:\n",
    "        df[cl] = df[cl].apply(lambda x: list(filter(lambda item: item,x.split(','))) if type(x)==str else x) #remove comma\n",
    "        df[cl] = df[cl].apply(lambda d: d if isinstance(d, list) else [0.0])#fill na\n",
    "        df[cl] = df[cl].apply(lambda x: list(map(float,x)) if type(x)==list else x)#convert all the list elements to float\n",
    "        df[cl] = df[cl].apply(lambda x:sum(x))#summ the ammount\n",
    "\n",
    "amt_sm_cl = ['CUR BAL - HIST','AMT OVERDUE - HIST','AMT PAID - HIST']\n",
    "amt_sum(amt_sm_cl,df_test_b)\n",
    "\n",
    "rd1_ts = df_test_b.groupby('ID')[amt_sm_cl].sum().reset_index()\n",
    "rd1_ts.rename(columns={'ID':'ID','CUR BAL - HIST':'Total_CUR_BAL','AMT OVERDUE - HIST':'Total_Overdue_Amt','AMT PAID - HIST':'Total_Paid_Amt'})\n",
    "\n",
    "bureua_data_f_ts =pd.merge(bureua_data_f_ts,rd1_ts,how='inner',on='ID',)\n",
    "bureua_data_f_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14745, 99)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textwrap\n",
    "def for_scN_DPD(nu):\n",
    "    if 'E' in nu:\n",
    "        nu = '%f'%np.float64(nu)\n",
    "        nu = textwrap.wrap(nu,3)\n",
    "        # print(nu)\n",
    "        nu =list(map(float,nu))\n",
    "\n",
    "    return sum(nu)\n",
    "\n",
    "#split into part of 3 digits\n",
    "#check if its string\n",
    "#if its not filter out keep only ints\n",
    "#sum the total of list\n",
    "def clean_DPD(x):\n",
    "    wp = textwrap.wrap(x,3)\n",
    "    if not all(str(s).isdigit() for s in wp):\n",
    "        # print(wp\n",
    "        wp = list(filter(lambda x: x not in ['XXX','DDD'], wp))\n",
    "        wp = list(map(int, wp))\n",
    "    else:\n",
    "        wp = list(map(int,wp))\n",
    "\n",
    "    return sum(wp)\n",
    "\n",
    "# for_scN_DPD(df_train_b['DPD - HIST'][26])\n",
    "df_test_b['DPD - HIST'].fillna('000',inplace=True)\n",
    "df_test_b['DPD - HIST'] = df_test_b['DPD - HIST'].apply(lambda x:for_scN_DPD(x) if 'E' in x else clean_DPD(x))\n",
    "rd3_ts = df_test_b.groupby('ID')['DPD - HIST'].sum().reset_index()\n",
    "\n",
    "rd3_ts.columns = ['ID','Total_DPD']\n",
    "bureua_data_f_ts =pd.merge(bureua_data_f_ts,rd3_ts,how='inner',on='ID',)\n",
    "bureua_data_f_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "print(len(result_a2_ts.columns))\n",
    "def drop_VC_BL_100(clm_nm,data_f):\n",
    "    for i in df_test_b[clm_nm].value_counts().loc[lambda x : x<100].index:\n",
    "        data_f.drop(clm_nm+'_%s'%i,axis=1,inplace=True)\n",
    "\n",
    "#now for CONTRIBUTOR-TYPE_ ACCOUNT-STATUS_ ASSET_CLASS_\n",
    "# for cl in ['ACCT-TYPE','CONTRIBUTOR-TYPE','ACCOUNT-STATUS','ASSET_CLASS']:\n",
    "#     drop_VC_BL_100(cl,result_a2)\n",
    "\n",
    "print(len(result_a2_ts.columns))\n",
    "\n",
    "for cl in ['ACCT-TYPE','CONTRIBUTOR-TYPE','ACCOUNT-STATUS','ASSET_CLASS']:\n",
    "    drop_VC_BL_100(cl,bureua_data_f_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mss_ct(ref_cl,ms_cl,df):\n",
    "    ''' function to fill the NaN values by mode method\n",
    "        Ex: in Particular State which is more frequent occured city\n",
    "            same for Area in Area\n",
    "                     SEX in Area\n",
    "                     Age in Area\n",
    "                     Salary in Area\n",
    "        ref_cl : Referece Column,\n",
    "        ref_nm : Element of refernce column, \n",
    "        df     : dataframe to oerform fill na operation\n",
    "    \n",
    "    '''\n",
    "    md = df[ms_cl].mode()[0]\n",
    "    frqnt_val = lambda x: x.fillna(x.value_counts().idxmax() if x.value_counts().max() >=1 else md , inplace = False)\n",
    "    df[ms_cl]=df.groupby([ref_cl])[ms_cl].apply(frqnt_val)\n",
    "    df[ms_cl] = df[ms_cl].fillna(df[ms_cl].value_counts().idxmax())\n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# def find_VC_St(ref_cl,ref_nm,tg):\n",
    "#     ''' ref_cl : Referece Column,\n",
    "#         ref_nm : Element of refernce column,\n",
    "#         tg     : column name to fill nan   '''\n",
    "#     vl_cm =df_test_data[df_test_data[ref_cl]==ref_nm][tg].value_counts()\n",
    "# #     print(vl_cm)\n",
    "#     re_nm_tg_cnt = (vl_cm.index[0],vl_cm[0])\n",
    "#     return re_nm_tg_cnt\n",
    "\n",
    "# print(find_VC_St('State','WEST BENGAL','City'),find_VC_St('State','ANDHRA PRADESH','City'))\n",
    "\n",
    "mss_ct('State','City',df_test_data)\n",
    "mss_ct('City','Area',df_test_data)\n",
    "mss_ct('Area','SEX',df_test_data)\n",
    "mss_ct('Area','AGE',df_test_data)\n",
    "mss_ct('Area','MonthlyIncome',df_test_data)\n",
    "\n",
    "# print(find_VC_St('State','WEST BENGAL','City'),find_VC_St('State','ANDHRA PRADESH','City'))\n",
    "df_test_data['MaturityDAte'].fillna(method='ffill',inplace=True)\n",
    "print(any(df_test_data.isna().sum()>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14745 entries, 0 to 14744\n",
      "Data columns (total 25 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   ID               14745 non-null  int64         \n",
      " 1   Frequency        14745 non-null  float64       \n",
      " 2   InstlmentMode    14745 non-null  float64       \n",
      " 3   LoanStatus       14745 non-null  float64       \n",
      " 4   PaymentMode      14745 non-null  float64       \n",
      " 5   BranchID         14745 non-null  int64         \n",
      " 6   Area             14745 non-null  float64       \n",
      " 7   Tenure           14745 non-null  int64         \n",
      " 8   AssetCost        14745 non-null  int64         \n",
      " 9   AmountFinance    14745 non-null  float64       \n",
      " 10  DisbursalAmount  14745 non-null  float64       \n",
      " 11  EMI              14745 non-null  float64       \n",
      " 12  DisbursalDate    14745 non-null  datetime64[ns]\n",
      " 13  MaturityDAte     14745 non-null  datetime64[ns]\n",
      " 14  AuthDate         14745 non-null  datetime64[ns]\n",
      " 15  AssetID          14745 non-null  int64         \n",
      " 16  ManufacturerID   14743 non-null  float64       \n",
      " 17  SupplierID       14745 non-null  int64         \n",
      " 18  LTV              14745 non-null  float64       \n",
      " 19  SEX              14745 non-null  float64       \n",
      " 20  AGE              14745 non-null  float64       \n",
      " 21  MonthlyIncome    14745 non-null  float64       \n",
      " 22  City             14745 non-null  float64       \n",
      " 23  State            14745 non-null  float64       \n",
      " 24  ZiPCODE          14744 non-null  float64       \n",
      "dtypes: datetime64[ns](3), float64(16), int64(6)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "df_test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "dro_clm = ['BranchID','AssetID','ManufacturerID','SupplierID','ZiPCODE']\n",
    "df_test_data.drop(dro_clm,axis=1,inplace=True)\n",
    "\n",
    "dt_cl = ['DisbursalDate','MaturityDAte','AuthDate']\n",
    "\n",
    "def handel_dt_ts(clm):\n",
    "    for cl in clm:\n",
    "        df_test_data[cl+'_Year'] = df_test_data[cl].dt.year.astype(float)\n",
    "        df_test_data[cl+'_Month']= df_test_data[cl].dt.month.astype(float)\n",
    "        df_test_data[cl+'_Week']= df_test_data[cl].dt.week.astype(float)\n",
    "        df_test_data[cl+'_Day']= df_test_data[cl].dt.day.astype(float)\n",
    "\n",
    "handel_dt_ts(dt_cl)\n",
    "df_test_data.drop(dt_cl,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = df_test_data['ID']\n",
    "target = df_train_data['Top-up Month']\n",
    "\n",
    "TUP_Mn = { id_en:i for i,id_en in enumerate(df_train_data['Top-up Month'].value_counts().index) }\n",
    "\n",
    "target = target.map(TUP_Mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before droping na (14745, 29)\n",
      "After droping na (14745, 29)\n"
     ]
    }
   ],
   "source": [
    "print('Before droping na',df_test_data.shape)\n",
    "df_test_data.dropna(inplace=True)\n",
    "print('After droping na',df_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before droping na (128655, 112)\n",
      "After droping na (128655, 112)\n"
     ]
    }
   ],
   "source": [
    "all_test = pd.merge(bureua_data_f_ts,df_test_data,how='inner',on='ID',)\n",
    "\n",
    "print('Before droping na',all_train.shape)\n",
    "all_test.dropna(inplace=True)\n",
    "print('After droping na',all_train.shape)\n",
    "all_test.drop(['ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128655, 112)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14745, 94)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trn in all_train.columns:\n",
    "    if trn not in all_test.columns:\n",
    "#         print(trn)\n",
    "        all_train.drop([trn],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rstne_100 = RandomForestClassifier(100, oob_score=True, n_jobs=-1, random_state=101)\n",
    "model_rstne_100.fit(all_train, target)\n",
    "y_pred_rftne_100 = model_rstne_100.predict(all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_sp =pd.read_csv('sample_submission_ejm25Dc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top-up Month'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb_sp.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUP_Mn = { id_en:i for i,id_en in enumerate(df_train_data['Top-up Month'].value_counts().index) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    106677\n",
       "1      8366\n",
       "2      3656\n",
       "3      3492\n",
       "4      3062\n",
       "5      2368\n",
       "6      1034\n",
       "Name: Top-up Month, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Top-up Service    106677\n",
       " > 48 Months           8366\n",
       "36-48 Months           3656\n",
       "24-30 Months           3492\n",
       "30-36 Months           3062\n",
       "18-24 Months           2368\n",
       "12-18 Months           1034\n",
       "Name: Top-up Month, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_data['Top-up Month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14392\n",
       "1      331\n",
       "2       11\n",
       "3        6\n",
       "5        3\n",
       "4        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred_rftne_100).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No Top-up Service': 0,\n",
       " ' > 48 Months': 1,\n",
       " '36-48 Months': 2,\n",
       " '24-30 Months': 3,\n",
       " '30-36 Months': 4,\n",
       " '18-24 Months': 5,\n",
       " '12-18 Months': 6}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TUP_Mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_map = {0:'No Top-up Service',\n",
    "            1:' > 48 Months',\n",
    "            2:'36-48 Months',\n",
    "            3:'24-30 Months',\n",
    "            4:'30-36 Months',\n",
    "            5:'18-24 Months'\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Top-up Service    14392\n",
       " > 48 Months           331\n",
       "36-48 Months            11\n",
       "24-30 Months             6\n",
       "18-24 Months             3\n",
       "30-36 Months             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred_rftne_100).map(test_map).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Top-up Service    14392\n",
       " > 48 Months           331\n",
       "36-48 Months            11\n",
       "24-30 Months             6\n",
       "18-24 Months             3\n",
       "30-36 Months             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rftne_dum = pd.Series(y_pred_rftne_100).map(test_map)\n",
    "y_pred_rftne_dum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rftne_100 = pd.Series(y_pred_rftne_100).map(test_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Top-up Service    14392\n",
       " > 48 Months           331\n",
       "36-48 Months            11\n",
       "24-30 Months             6\n",
       "18-24 Months             3\n",
       "30-36 Months             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rftne_100.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv = pd.DataFrame({sb_sp.columns[0]:test_id,\n",
    "                       sb_sp.columns[1]:y_pred_rftne_100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Top-up Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>No Top-up Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>No Top-up Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>No Top-up Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>No Top-up Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119</td>\n",
       "      <td>No Top-up Service</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID       Top-up Month\n",
       "0    4  No Top-up Service\n",
       "1    5  No Top-up Service\n",
       "2    6  No Top-up Service\n",
       "3   25  No Top-up Service\n",
       "4  119  No Top-up Service"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14745, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14745, 94)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_csv.to_csv('submission_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pickle-mixin\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vishal.nadagiri\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "saved_md = pickle.load(open('model_rstne_100.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_svd = saved_md.predict(all_test)\n",
    "\n",
    "y_svd_100 = pd.Series(y_svd).map(test_map)\n",
    "\n",
    "to_csv = pd.DataFrame({sb_sp.columns[0]:test_id,\n",
    "                       sb_sp.columns[1]:y_pred_rftne_100})\n",
    "\n",
    "to_csv.to_csv('submission_1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
